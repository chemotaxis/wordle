{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83d2149-48e6-4a6d-ba95-4d68752b0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import string\n",
    "from collections import defaultdict, Counter\n",
    "from collections.abc import Callable\n",
    "from itertools import filterfalse\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6a362-d977-4f36-8945-0bd1d2ac7f25",
   "metadata": {},
   "source": [
    "https://www.nytimes.com/games/wordle/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87639a9-fd41-490a-82f5-6872fcab8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_exc(words: list[str], \n",
    "            letter_groups: dict[str, set[str]], \n",
    "            include: str, \n",
    "            exclude: str) -> list[str]:\n",
    "    \"\"\"Filters words based on the characters in include and exclude.\n",
    "    \n",
    "    If include and exclude are empty, inc_exc returns the same \n",
    "    list of words, albeit a copy of the original list with duplicate words removed.\n",
    "    \n",
    "    Args:\n",
    "        words: A list of words.\n",
    "        letter_groups: A mapping between a character in a word and \n",
    "            a subset from words that contain that character.\n",
    "        include: A string of characters that must be contained in all the output words.\n",
    "        exclude: A string of characters that must _not_ be contained in any output words.\n",
    "        \n",
    "    Returns:\n",
    "        A list of filtered words where each word contains all the characters in include, but \n",
    "        does not have the characters listed in exclude.\n",
    "    \"\"\"\n",
    "    include, exclude = set(include), set(exclude)\n",
    "    possible = set(words)\n",
    "    \n",
    "    for ch in include:\n",
    "        possible &= letter_groups[ch]\n",
    "\n",
    "    print(f'Words that include {include}: {len(possible):,}')\n",
    "    for ch in exclude:\n",
    "        possible -= letter_groups[ch]\n",
    "\n",
    "    print(f'Words that include {include}, but exclude {exclude}: {len(possible):,}')\n",
    "    \n",
    "    return list(possible)\n",
    "\n",
    "def group_by_letter(words: list[str], char_set: str=string.ascii_lowercase) -> dict[str, set[str]]:\n",
    "    \"\"\"Groups words into sets based on what character is contained in the word.\n",
    "    \n",
    "    Args:\n",
    "        words: A list of words.\n",
    "        char_set: A string containing all the characters used to compose words.\n",
    "        \n",
    "    Returns:\n",
    "        A mapping between each character in char_set and \n",
    "        a subset of words that contain that character.\n",
    "    \"\"\"\n",
    "    letters = defaultdict(set)\n",
    "    for ch in char_set:\n",
    "        for word in words:\n",
    "            if ch in word:\n",
    "                letters[ch].add(word)\n",
    "    return letters\n",
    "\n",
    "class Possible(object):\n",
    "    def __init__(self, iterable: list[str]):\n",
    "        print(f'Sorting values')\n",
    "        iterable.sort()\n",
    "        self.values = iterable\n",
    "    \n",
    "    def distinct_letters_only(self):\n",
    "        self.filter(lambda word: len(set(word)) == len(word))\n",
    "        \n",
    "    def filter(self, condition: Callable[[str], bool]):\n",
    "        self.values = list(filter(condition, self.values))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Possible({self.values})'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b32e347-bf62-4d20-bff7-8b06ae961deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words: 370,105\n",
      "Five-letter words: 15,920\n"
     ]
    }
   ],
   "source": [
    "words = [word.strip() for word in fileinput.input('words_alpha.txt')]\n",
    "print(f'All words: {len(words):,}')\n",
    "\n",
    "five_letter_words = [word for word in words if len(word) == 5]\n",
    "five_letters_grouped = group_by_letter(five_letter_words)\n",
    "five = lambda inc, exc: inc_exc(five_letter_words, five_letters_grouped, inc, exc)\n",
    "\n",
    "print(f'Five-letter words: {len(five_letter_words):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde6880-f1fb-4409-94f8-a3f1703e40be",
   "metadata": {},
   "source": [
    "## Guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51deeaa0-71b9-49b2-b764-6e4651f43ca7",
   "metadata": {},
   "source": [
    "### Method 1: Uniformally random word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59425528-a18a-42ef-a496-56ae2394ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_letters = list(filter(lambda word: len(set(word)) == len(word), five_letter_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423f1404-887f-41e7-9fcf-0bd918a7b3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xenia'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(distinct_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657f678-f9b5-4ee0-91d3-1ad6b930ebf0",
   "metadata": {},
   "source": [
    "### Method 2: Pick words with letters that occur the most\n",
    "\n",
    "The end goal is to eliminate as many words as possible.  For the first guess, if we pick a word that has letters that occur the most, we can see if any of those letters can be discarded.  Because we used the most frequently used letters, we theoretically eliminate more words per letter using these letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ab5433e-9fd1-4eb6-a638-eeac92c9f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = Counter()\n",
    "for word in five_letter_words:\n",
    "    for ch in word:\n",
    "        hist[ch] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3a39b83-caa8-4cd8-bb58-02934e1a7767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 8393),\n",
       " ('e', 7802),\n",
       " ('s', 6537),\n",
       " ('o', 5219),\n",
       " ('r', 5144),\n",
       " ('i', 5067),\n",
       " ('l', 4247),\n",
       " ('t', 4189),\n",
       " ('n', 4044),\n",
       " ('u', 3361)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4115af47-487c-4ba1-b5c6-195d414b682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that include {'n', 'o', 's', 'e'}: 64\n",
      "Words that include {'n', 'o', 's', 'e'}, but exclude set(): 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['omens',\n",
       " 'osone',\n",
       " 'noser',\n",
       " 'onces',\n",
       " 'norse',\n",
       " 'snore',\n",
       " 'shone',\n",
       " 'doesn',\n",
       " 'nosey',\n",
       " 'opens',\n",
       " 'ornes',\n",
       " 'secno',\n",
       " 'seton',\n",
       " 'peons',\n",
       " 'somne',\n",
       " 'ovens',\n",
       " 'hones',\n",
       " 'slone',\n",
       " 'zones',\n",
       " 'nones',\n",
       " 'tones',\n",
       " 'solen',\n",
       " 'segno',\n",
       " 'snoke',\n",
       " 'kenos',\n",
       " 'sones',\n",
       " 'genos',\n",
       " 'enows',\n",
       " 'seron',\n",
       " 'senor',\n",
       " 'meson',\n",
       " 'pones',\n",
       " 'snoek',\n",
       " 'neons',\n",
       " 'noose',\n",
       " 'nodes',\n",
       " 'noels',\n",
       " 'tenso',\n",
       " 'aeons',\n",
       " 'eosin',\n",
       " 'nemos',\n",
       " 'bones',\n",
       " 'stone',\n",
       " 'omnes',\n",
       " 'senso',\n",
       " 'sonde',\n",
       " 'steno',\n",
       " 'noise',\n",
       " 'cosen',\n",
       " 'noses',\n",
       " 'soken',\n",
       " 'jones',\n",
       " 'enols',\n",
       " 'xenos',\n",
       " 'lenos',\n",
       " 'onset',\n",
       " 'scone',\n",
       " 'ebons',\n",
       " 'cones',\n",
       " 'nomes',\n",
       " 'notes',\n",
       " 'nosed',\n",
       " 'hosen',\n",
       " 'owsen']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible = five('eson', '')\n",
    "possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dd5bc-d094-4e05-9c73-4b728cede234",
   "metadata": {},
   "source": [
    "## Filter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96afe925-aa65-4300-9b89-d6b2b69bae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with five letters: 15,920\n"
     ]
    }
   ],
   "source": [
    "print(f'Words with five letters: {len(five_letter_words):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18261736-3af1-474b-8d65-5a8287303695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that include {'p', 'r', 's', 'a'}: 62\n",
      "Words that include {'p', 'r', 's', 'a'}, but exclude {'x', 'g', 'n', 'e', 'i', 'y'}: 36\n",
      "Sorting values\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Possible(['scrap', 'shrap', 'strap'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Possible(five('arsp', 'xeniyg'))\n",
    "\n",
    "words.filter(lambda word: word[0] != 'r' and word[1] != 'a' and word[2] != 's' and word[3] != 'p')\n",
    "words.filter(lambda word: word[1] != 'r' and word[2] != 'a' and word[3] != 's' and word[4] == 'p')\n",
    "# words.distinct_letters_only()\n",
    "\n",
    "print(len(words))\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479857b6-bed6-4fce-b684-d94317fe8dc9",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33490777-7888-4280-974c-7d80feba890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "\n",
    "Result = namedtuple('Result', ['wordle', 'date', 'words', 'regular', 'high_contrast'])\n",
    "def println(*objects, **kw):\n",
    "    print(*objects, end='\\n\\n', **kw)\n",
    "    \n",
    "def print_results(results, show_rowid=False):\n",
    "    def header(head, rowid):\n",
    "        msg = f'{head}'\n",
    "        if show_rowid:\n",
    "            msg += f' rowid: {rowid}'\n",
    "            \n",
    "        return msg\n",
    "        \n",
    "    for rowid, *result in results:\n",
    "        result = Result(*result)\n",
    "\n",
    "        hi = result.high_contrast.splitlines()\n",
    "        words = result.words.splitlines()\n",
    "        \n",
    "        print(header(hi[0], rowid))\n",
    "        for line, word in itertools.zip_longest(itertools.islice(hi, 2, None), words, fillvalue=''):\n",
    "            print(f'{line} {word}')\n",
    "        print()\n",
    "    \n",
    "con = sqlite3.connect('wordle.db')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0c92d3f-92be-40b4-9d47-cca2d10ee180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordle 336 5/6*\n",
      "â¬œâ¬œâ¬œâ¬œðŸŸ¦ xenia\n",
      "ðŸŸ¦ðŸŸ¦ðŸŸ¦ðŸŸ¦â¬œ raspy\n",
      "â¬œðŸŸ¦ðŸŸ¦ðŸŸ¦ðŸŸ§ grasp\n",
      "ðŸŸ§â¬œðŸŸ§ðŸŸ§ðŸŸ§ strap\n",
      "ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ scrap\n",
      "\n",
      "Wordle 335 4/6*\n",
      "â¬œâ¬œâ¬œðŸŸ§â¬œ liven\n",
      "â¬œâ¬œðŸŸ¦ðŸŸ§â¬œ screw\n",
      "ðŸŸ¦ðŸŸ¦â¬œðŸŸ§ðŸŸ§ amber\n",
      "ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ gamer\n",
      "\n",
      "Wordle 334 4/6*\n",
      "ðŸŸ¦â¬œâ¬œðŸŸ¦â¬œ apple\n",
      "â¬œðŸŸ¦ðŸŸ¦â¬œðŸŸ§ malus\n",
      "ðŸŸ¦â¬œðŸŸ§â¬œðŸŸ§ loans\n",
      "ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ glass\n",
      "\n",
      "Wordle 333 3/6*\n",
      "â¬œðŸŸ¦â¬œðŸŸ¦â¬œ noise\n",
      "ðŸŸ§â¬œâ¬œâ¬œðŸŸ¦ salvo\n",
      "ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ scour\n",
      "\n",
      "Wordle 332 5/6*\n",
      "â¬œâ¬œâ¬œâ¬œðŸŸ¦ psoae\n",
      "â¬œâ¬œâ¬œðŸŸ¦â¬œ xylem\n",
      "â¬œðŸŸ§â¬œâ¬œâ¬œ hertz\n",
      "â¬œðŸŸ§ðŸŸ§ðŸŸ¦ðŸŸ¦ feign\n",
      "ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ being\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_recent = cur.execute('''SELECT ROWID, * FROM results ORDER BY ROWID DESC''').fetchall()[:5]\n",
    "print_results(most_recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a41b0-ece1-4346-bc98-6e5ebb94f1cb",
   "metadata": {},
   "source": [
    "### Create table\n",
    "\n",
    "Only need to do once.  Uncomment to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b3f029-8188-4257-8831-3b636d4ec0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute('''\n",
    "# CREATE TABLE results \n",
    "# (wordle, date, words, regular, high_contrast)\n",
    "# ''')\n",
    "# con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f5381-8999-482f-b6c5-38bc876496ea",
   "metadata": {},
   "source": [
    "### Save result\n",
    "\n",
    "To keep it simple, everything is stored as TEXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45244937-5569-4050-a6b1-59f9c0fa6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "INSERT INTO results VALUES (\n",
    "'336', '2022-05-21', \n",
    "'xenia\n",
    "raspy\n",
    "grasp\n",
    "strap\n",
    "scrap', \n",
    "'Wordle 336 5/6*\n",
    "\n",
    "â¬œâ¬œâ¬œâ¬œðŸŸ¨\n",
    "ðŸŸ¨ðŸŸ¨ðŸŸ¨ðŸŸ¨â¬œ\n",
    "â¬œðŸŸ¨ðŸŸ¨ðŸŸ¨ðŸŸ©\n",
    "ðŸŸ©â¬œðŸŸ©ðŸŸ©ðŸŸ©\n",
    "ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©', \n",
    "'Wordle 336 5/6*\n",
    "\n",
    "â¬œâ¬œâ¬œâ¬œðŸŸ¦\n",
    "ðŸŸ¦ðŸŸ¦ðŸŸ¦ðŸŸ¦â¬œ\n",
    "â¬œðŸŸ¦ðŸŸ¦ðŸŸ¦ðŸŸ§\n",
    "ðŸŸ§â¬œðŸŸ§ðŸŸ§ðŸŸ§\n",
    "ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§ðŸŸ§'\n",
    ")''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8b1ac-d8d9-4fbb-b4c8-90b5fb604614",
   "metadata": {},
   "source": [
    "### SQL utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929e9663-f30f-477e-8e5f-349fdb65c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute('''DELETE FROM results WHERE wordle='325' ''')\n",
    "# con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2fe2ff7-f095-47a4-8e79-4d4381e28d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close connection to database\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
